{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"GPU setup\"\"\"\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Imports, define RBM model\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "from utils.data import mnist_eager\n",
    "from utils.rbm import repeated_gibbs, gibbs_update_brbm, energy_rbm\n",
    "from utils.viz import random_sample_grid, img_grid_npy, imshow\n",
    "\n",
    "\n",
    "# data\n",
    "batch_size = 256\n",
    "train_steps = 1500\n",
    "\n",
    "data = mnist_eager(\"data/mnist_train\", batch_size)\n",
    "\n",
    "\n",
    "# model\n",
    "mode = \"pcd\"\n",
    "if mode not in [\"pcd\", \"cd\", \"naive\"]:\n",
    "    raise ValueError(\"uh oh!\")\n",
    "\n",
    "n_h = 1000\n",
    "w_vh = tf.get_variable(\"w_vh\", [32*32, n_h], tf.float32)\n",
    "b_v = tf.get_variable(\"b_v\", [32*32], tf.float32,\n",
    "                      initializer=tf.zeros_initializer)\n",
    "b_h = tf.get_variable(\"b_h\", [n_h], tf.float32,\n",
    "                      initializer=tf.zeros_initializer)\n",
    "weights = [w_vh, b_v, b_h]\n",
    "\n",
    "# TODO adapt to data having image dimensions \n",
    "# compute marginal for better sampling\n",
    "data_once = mnist_eager(\"data/mnist_train\", 60000, train=False)\n",
    "marginals = tf.reduce_mean([img for (img, _) in data_once], axis=[0,1])\n",
    "print(marginals.shape)\n",
    "\n",
    "\n",
    "start_sampler = tf.distributions.Bernoulli(probs=0.5, dtype=tf.float32)\n",
    "marginal_sampler = tf.distributions.Bernoulli(probs=marginals, dtype=tf.float32)\n",
    "\n",
    "#opt = tf.train.GradientDescentOptimizer(0.1)\n",
    "opt = tf.train.AdamOptimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train\"\"\"\n",
    "if mode == \"pcd\":\n",
    "    v_sampled = marginal_sampler.sample(batch_size)\n",
    "    h_sampled = start_sampler.sample([batch_size, n_h])\n",
    "for step, (img_batch, _) in enumerate(data):\n",
    "    if step > train_steps:\n",
    "        break\n",
    "\n",
    "    v_data = img_batch\n",
    "    #_, h_data = gibbs_update_brbm((v_data, h_random), w_vh, b_v, b_h)\n",
    "    h_data = tf.nn.sigmoid(tf.matmul(v_data, w_vh) + b_h)\n",
    "\n",
    "    if mode == \"cd\":\n",
    "        v_sampled, h_sampled = repeated_gibbs(\n",
    "            (v_data, h_data), 20, gibbs_update_brbm,\n",
    "            w_vh=w_vh, b_v=b_v, b_h=b_h)\n",
    "    elif mode == \"pcd\":\n",
    "        v_sampled, h_sampled = repeated_gibbs(\n",
    "            (v_sampled, h_sampled), 20, gibbs_update_brbm,\n",
    "            w_vh=w_vh, b_v=b_v, b_h=b_h)\n",
    "    else:\n",
    "        v_random = marginal_sampler.sample(img_batch.shape[0])\n",
    "        # this is just a dummy\n",
    "        h_random = start_sampler.sample([img_batch.shape[0], n_h])\n",
    "        v_sampled, h_sampled = repeated_gibbs(\n",
    "            (v_random, h_random), 200, gibbs_update_brbm,\n",
    "            w_vh=w_vh, b_v=b_v, b_h=b_h)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits_pos = tf.reduce_mean(-energy_rbm(v_data, h_data, w_vh, b_v, b_h))\n",
    "        logits_neg = tf.reduce_mean(\n",
    "            -energy_rbm(v_sampled, h_sampled, w_vh, b_v, b_h))\n",
    "        loss = -(logits_pos - logits_neg)\n",
    "    grads = tape.gradient(loss, weights)\n",
    "    opt.apply_gradients(zip(grads, weights))\n",
    "    if not step % 50:\n",
    "        print(\"Step\", step)\n",
    "        print(\"Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"weights...\")\n",
    "for img in w_vh.numpy().T:\n",
    "    absmax = np.max(np.abs(img))\n",
    "    plt.imshow(img.reshape((32,32)), vmin=-absmax, vmax=absmax, cmap=\"RdBu_r\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"random samples\"\"\"\n",
    "v_random = marginal_sampler.sample([16])\n",
    "h_random = start_sampler.sample([16, n_h])\n",
    "img_sample, _ = repeated_gibbs(\n",
    "        (v_random, h_random), 200, gibbs_update_brbm,\n",
    "        w_vh=w_vh, b_v=b_v, b_h=b_h)\n",
    "\n",
    "img_sample = [img.numpy().reshape((32, 32)) for img in img_sample]\n",
    "grid = img_grid_npy(img_sample, 4, 4, normalize=False)\n",
    "imshow(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"GPU setup\"\"\"\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Imports, define GAN\"\"\"\n",
    "from itertools import product\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from utils.cppn import make_grid, format_batch\n",
    "from utils.data import tfr_dataset_eager, parse_img_label_tfr\n",
    "from utils.math import compute_mmd\n",
    "from utils.models import enc_conv_mnist, enc_fc_mnist\n",
    "from utils.viz import random_sample_grid, img_grid_npy, imshow\n",
    "\n",
    "\n",
    "# data\n",
    "svhn = True\n",
    "batch_size = 256  # this is a \"half batch\"!\n",
    "train_steps = 5000 if svhn else 1500\n",
    "dim_noise = 100\n",
    "label_smoothing = 0.9\n",
    "\n",
    "if svhn:\n",
    "    train_files = [\"/cache/tfrs/svhn_train.tfr\", \"/cache/tfrs/svhn_extra.tfr\"]\n",
    "    test_files = [\"/cache/tfrs/svhn_test.tfr\"]\n",
    "    parse_fn = lambda x: parse_img_label_tfr(x, (32, 32, 3))\n",
    "else:\n",
    "    train_files = [\"/cache/tfrs/mnist_train.tfr\"]\n",
    "    test_files = [\"/cache/tfrs/mnist_test.tfr\"]\n",
    "    parse_fn = lambda x: parse_img_label_tfr(x, (32, 32, 1))\n",
    "\n",
    "data = tfr_dataset_eager(train_files, batch_size, parse_fn, shufrep=600000 if svhn else 60000)\n",
    "\n",
    "conv = False\n",
    "if conv:\n",
    "    discriminator = enc_conv_mnist(1, use_bn=True)\n",
    "else:\n",
    "    discriminator = enc_fc_mnist(1, use_bn=True)\n",
    "    \n",
    "poses = make_grid(32, 2)\n",
    "poses = tf.constant(poses, dtype=tf.float32)\n",
    "\n",
    "\n",
    "cppn = tf.keras.Sequential([tf.keras.layers.Dense(12, tf.sin),\n",
    "                             #tf.keras.layers.Dense(6, tf.sin),\n",
    "                             tf.keras.layers.Dense(12, lambda x: tf.exp(-x**2)),\n",
    "                             tf.keras.layers.Dense(3 if svhn else 1, lambda x: tf.nn.sigmoid(5*x))])\n",
    "cppn.build((None, 2+dim_noise))\n",
    "\n",
    "\n",
    "def noise_fn(n_samples): return tf.random.uniform([n_samples, dim_noise], minval=-1, maxval=1)\n",
    "\n",
    "\n",
    "#loss = tf.losses.BinaryCrossentropy(from_logits=True)\n",
    "loss = tf.losses.MeanSquaredError()\n",
    "\n",
    "gen_opt = tf.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "disc_opt = tf.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train GAN\"\"\"\n",
    "\n",
    "@tf.function\n",
    "def train(batch, g_loss):\n",
    "    batch_dim = tf.shape(batch)[0]\n",
    "    if True:\n",
    "        # prepare mixed batch for discriminator training\n",
    "        # For batchnorm to work better, we feed only real images, then only \n",
    "        # generated ones and then average the gradients\n",
    "        \n",
    "        noise = noise_fn(batch_dim)\n",
    "        combined_batch = format_batch(noise, poses)\n",
    "        \n",
    "        gen_batch = cppn(combined_batch)\n",
    "        gen_batch = tf.reshape(gen_batch, [batch_dim, 32, 32, 3 if svhn else 1])\n",
    "        \n",
    "        real_labels = label_smoothing*tf.ones([batch_dim, 1])\n",
    "        gen_labels = tf.zeros([batch_dim, 1])\n",
    "        with tf.GradientTape() as d_tape:\n",
    "            d_loss_real = loss(real_labels, discriminator(batch))\n",
    "            d_loss_fake = loss(gen_labels, discriminator(gen_batch))\n",
    "            d_loss = 0.5 * (d_loss_real + d_loss_fake)\n",
    "        d_grads = d_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "        disc_opt.apply_gradients(zip(d_grads, discriminator.trainable_variables))\n",
    "    else:\n",
    "        d_loss = 0.0\n",
    "    \n",
    "    # fresh generated batch for generator training\n",
    "    with tf.GradientTape(watch_accessed_variables=False) as g_tape:\n",
    "        for vari in cppn.trainable_variables:\n",
    "            g_tape.watch(vari)\n",
    "            \n",
    "        noise2 = noise_fn(2*batch_dim)\n",
    "        combined_batch2 = format_batch(noise2, poses)\n",
    "        gen_only_batch = cppn(combined_batch2)\n",
    "        gen_only_batch = tf.reshape(gen_only_batch, [2*batch_dim, 32, 32, 3 if svhn else 1])\n",
    "        g_loss = loss(label_smoothing*tf.ones([2*batch_dim, 1]),\n",
    "                      discriminator(gen_only_batch))\n",
    "    g_grads = g_tape.gradient(g_loss, cppn.trainable_variables)\n",
    "    gen_opt.apply_gradients(zip(g_grads, cppn.trainable_variables))\n",
    "    \n",
    "    return g_loss, d_loss\n",
    "\n",
    "\n",
    "tf.keras.backend.set_learning_phase(1)\n",
    "g_loss = tf.constant(0.5, dtype=tf.float32)\n",
    "for step, (img_batch, _) in enumerate(data):\n",
    "    if step > train_steps:\n",
    "        break\n",
    "\n",
    "    g_loss, d_loss = train(img_batch, g_loss)\n",
    "    \n",
    "    if not step % 50:\n",
    "        print(\"Step\", step)\n",
    "        print(\"Gen Loss\", g_loss)\n",
    "        print(\"Disc Loss\", d_loss)\n",
    "\n",
    "tf.keras.backend.set_learning_phase(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Generate samples\"\"\"\n",
    "\n",
    "tf.keras.backend.set_learning_phase(0)\n",
    "\n",
    "noise = noise_fn(7*7)\n",
    "pose_batch = tf.tile(poses, [7*7, 1])\n",
    "noise_batch = repeat(noise, tf.shape(poses)[0])\n",
    "combined_batch = tf.concat([pose_batch, noise_batch], axis=1)\n",
    "\n",
    "gen_batch = cppn(combined_batch)\n",
    "gen_batch = tf.reshape(gen_batch, [7*7, 32, 32, -1])\n",
    "\n",
    "grid = img_grid_npy(gen_batch.numpy(), 7, 7, normalize=False)\n",
    "imshow(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_learning_phase(0)\n",
    "\n",
    "hr = 1024\n",
    "noise = noise_fn(1)\n",
    "poseshr = make_grid(hr, 2, -256, 255)\n",
    "poseshr = tf.constant(poseshr, dtype=tf.float32)\n",
    "\n",
    "combined_batch = format_batch(noise, poseshr)\n",
    "\n",
    "gen_batch = cppn(combined_batch)\n",
    "gen_batch = tf.reshape(gen_batch, [hr, hr, -1])\n",
    "\n",
    "imshow(gen_batch, figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
